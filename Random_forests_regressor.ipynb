{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e487cceb",
   "metadata": {},
   "source": [
    "### Random forests regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567d4ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'split', 'V', 'A', 'D', 'text'], dtype='object')\n",
      "\n",
      "(9906, 6)\n",
      "                    id  split     V     A     D  \\\n",
      "0  110CYL068_1036_1079  train  3.00  3.00  3.20   \n",
      "1  110CYL068_1079_1110   test  2.80  3.10  2.80   \n",
      "2  110CYL068_1127_1130  train  3.00  3.00  3.00   \n",
      "3  110CYL068_1137_1188  train  3.44  3.00  3.22   \n",
      "4  110CYL068_1189_1328  train  3.55  3.27  3.46   \n",
      "\n",
      "                                                text  \n",
      "0        Remember what she said in my last letter? \"  \n",
      "1                          If I wasn't working here.  \n",
      "2                                                ..\"  \n",
      "3  Goodwill helps people get off of public assist...  \n",
      "4  Sherry learned through our Future Works class ...  \n",
      "\n",
      "id        object\n",
      "split     object\n",
      "V        float64\n",
      "A        float64\n",
      "D        float64\n",
      "text      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "data_01=pd.read_csv('Emo_Bank_VAD.csv')\n",
    "\n",
    "print(data_01.columns)\n",
    "print('')\n",
    "print(data_01.shape)\n",
    "print(data_01.head())\n",
    "print('')\n",
    "print(data_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb42184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, split, V, A, D, text]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "split    0\n",
       "V        0\n",
       "A        0\n",
       "D        0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_rows = data_01[data_01['text'].isnull()]\n",
    "print(null_rows)\n",
    "data_01 = data_01.dropna(subset=['text'])\n",
    "data_01.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a466b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: (8023,) (892,) (991,) (8023, 3) (892, 3) (991, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_01[\"text\"], data_01[[\"V\", \"A\", \"D\"]], test_size=0.1, shuffle=True, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, shuffle=True, random_state=1)\n",
    "print(\"Data shapes:\", x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "#Vectorize \"text\" data\n",
    "tfidf = TfidfVectorizer()\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_val_tfidf = tfidf.transform(x_val)\n",
    "x_test_tfidf = tfidf.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa3416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best hyperparameters: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 100}\n",
      "Best parameters: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 100}\n",
      "\n",
      "Train Dataset:\n",
      "RMSE for V: 0.13\n",
      "RMSE for A: 0.11\n",
      "RMSE for D: 0.09\n",
      "\n",
      "MAE for V: 0.09\n",
      "MAE for A: 0.08\n",
      "MAE for D: 0.06\n",
      "\n",
      "MSE for V: 0.02\n",
      "MSE for A: 0.01\n",
      "MSE for D: 0.01\n",
      "\n",
      "Validation Dataset:\n",
      "RMSE for V: 0.3\n",
      "RMSE for A: 0.26\n",
      "RMSE for D: 0.22\n",
      "\n",
      "MAE for V: 0.22\n",
      "MAE for A: 0.19\n",
      "MAE for D: 0.17\n",
      "\n",
      "MSE for V: 0.09\n",
      "MSE for A: 0.07\n",
      "MSE for D: 0.05\n",
      "\n",
      "Test Dataset:\n",
      "RMSE for V: 0.31\n",
      "RMSE for A: 0.26\n",
      "RMSE for D: 0.22\n",
      "\n",
      "MAE for V: 0.22\n",
      "MAE for A: 0.19\n",
      "MAE for D: 0.16\n",
      "\n",
      "MSE for V: 0.09\n",
      "MSE for A: 0.07\n",
      "MSE for D: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor with n_jobs=1 to avoid threading issues\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=1)\n",
    "\n",
    "# Use MultiOutputRegressor to predict multiple outputs\n",
    "multi_rf = MultiOutputRegressor(rf)\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100],  # Fewer trees\n",
    "    'estimator__max_depth': [None, 10],  # Limit depth\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "    'estimator__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning with fewer jobs\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=multi_rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Get the best parameters from the GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on training, validation, and test datasets\n",
    "y_train_pred =best_model.predict(x_train_tfidf)\n",
    "y_val_pred = best_model.predict(x_val_tfidf)\n",
    "y_test_pred = best_model.predict(x_test_tfidf)\n",
    "\n",
    "# Convert targets and predictions to numpy arrays \n",
    "y_train_np = y_train.to_numpy()\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "y_train_pred_np = np.array(y_train_pred)\n",
    "y_val_pred_np = np.array(y_val_pred)\n",
    "y_test_pred_np = np.array(y_test_pred)\n",
    "\n",
    "\n",
    "# Evaluate the model performance using RMSE, MSE, and MAE\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    metrics = {}\n",
    "    metrics['RMSE_V'] = rmse(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['RMSE_A'] = rmse(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['RMSE_D'] = rmse(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    metrics['MAE_V'] = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['MAE_A'] = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['MAE_D'] = mean_absolute_error(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    metrics['MSE_V'] = mean_squared_error(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['MSE_A'] = mean_squared_error(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['MSE_D'] = mean_squared_error(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate performance metrics for train, validation, and test datasets\n",
    "train_metrics = evaluate_performance(y_train_np, y_train_pred_np)\n",
    "val_metrics = evaluate_performance(y_val_np, y_val_pred_np)\n",
    "test_metrics = evaluate_performance(y_test_np, y_test_pred_np)\n",
    "\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}\\n')\n",
    "\n",
    "print(\"Train Dataset:\")\n",
    "print(f'RMSE for V: {round(train_metrics[\"RMSE_V\"], 2)}')\n",
    "print(f'RMSE for A: {round(train_metrics[\"RMSE_A\"], 2)}')\n",
    "print(f'RMSE for D: {round(train_metrics[\"RMSE_D\"], 2)}\\n')\n",
    "print(f'MAE for V: {round(train_metrics[\"MAE_V\"], 2)}')\n",
    "print(f'MAE for A: {round(train_metrics[\"MAE_A\"], 2)}')\n",
    "print(f'MAE for D: {round(train_metrics[\"MAE_D\"], 2)}\\n')\n",
    "print(f'MSE for V: {round(train_metrics[\"MSE_V\"], 2)}')\n",
    "print(f'MSE for A: {round(train_metrics[\"MSE_A\"], 2)}')\n",
    "print(f'MSE for D: {round(train_metrics[\"MSE_D\"], 2)}\\n')\n",
    "\n",
    "print(\"Validation Dataset:\")\n",
    "print(f'RMSE for V: {round(val_metrics[\"RMSE_V\"], 2)}')\n",
    "print(f'RMSE for A: {round(val_metrics[\"RMSE_A\"], 2)}')\n",
    "print(f'RMSE for D: {round(val_metrics[\"RMSE_D\"], 2)}\\n')\n",
    "print(f'MAE for V: {round(val_metrics[\"MAE_V\"], 2)}')\n",
    "print(f'MAE for A: {round(val_metrics[\"MAE_A\"], 2)}')\n",
    "print(f'MAE for D: {round(val_metrics[\"MAE_D\"], 2)}\\n')\n",
    "print(f'MSE for V: {round(val_metrics[\"MSE_V\"], 2)}')\n",
    "print(f'MSE for A: {round(val_metrics[\"MSE_A\"], 2)}')\n",
    "print(f'MSE for D: {round(val_metrics[\"MSE_D\"], 2)}\\n')\n",
    "\n",
    "print(\"Test Dataset:\")\n",
    "print(f'RMSE for V: {round(test_metrics[\"RMSE_V\"], 2)}')\n",
    "print(f'RMSE for A: {round(test_metrics[\"RMSE_A\"], 2)}')\n",
    "print(f'RMSE for D: {round(test_metrics[\"RMSE_D\"], 2)}\\n')\n",
    "print(f'MAE for V: {round(test_metrics[\"MAE_V\"], 2)}')\n",
    "print(f'MAE for A: {round(test_metrics[\"MAE_A\"], 2)}')\n",
    "print(f'MAE for D: {round(test_metrics[\"MAE_D\"], 2)}\\n')\n",
    "print(f'MSE for V: {round(test_metrics[\"MSE_V\"], 2)}')\n",
    "print(f'MSE for A: {round(test_metrics[\"MSE_A\"], 2)}')\n",
    "print(f'MSE for D: {round(test_metrics[\"MSE_D\"], 2)}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6008d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Comparison:\n",
      "       V     A     D  V_pred  A_pred  D_pred\n",
      "0  3.00  2.70  3.10    3.03    2.86    3.08\n",
      "1  2.50  3.10  2.80    2.71    3.05    2.92\n",
      "2  2.30  3.10  2.80    2.48    3.15    2.85\n",
      "3  3.56  3.33  3.11    3.44    3.24    3.12\n",
      "4  3.00  3.00  3.00    3.01    2.99    3.03\n",
      "\n",
      "Validation Data Comparison:\n",
      "       V     A     D  V_pred  A_pred  D_pred\n",
      "0  3.10  3.10  3.80    3.26    3.15    2.84\n",
      "1  2.90  2.90  2.90    3.00    3.01    3.11\n",
      "2  3.00  3.43  3.43    2.70    3.05    2.98\n",
      "3  3.11  3.00  3.22    3.02    2.98    3.04\n",
      "4  3.00  3.20  3.10    3.02    3.00    3.09\n",
      "\n",
      "Test Data Comparison:\n",
      "      V     A    D  V_pred  A_pred  D_pred\n",
      "0  2.9  2.20  2.9    3.04    2.93    2.99\n",
      "1  2.6  3.20  2.9    2.89    3.12    2.99\n",
      "2  3.0  2.86  3.0    3.01    3.00    3.04\n",
      "3  2.9  2.70  3.1    3.07    2.99    3.00\n",
      "4  3.0  2.78  3.0    3.02    2.96    3.07\n"
     ]
    }
   ],
   "source": [
    "#Create tables to compare predicted and real values\n",
    "\n",
    "# Convert predictions to DataFrames and round to two decimals\n",
    "y_train_pred_df = pd.DataFrame(y_train_pred, columns=[\"V_pred\", \"A_pred\", \"D_pred\"]).round(2)\n",
    "y_val_pred_df = pd.DataFrame(y_val_pred, columns=[\"V_pred\", \"A_pred\", \"D_pred\"]).round(2)\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns=[\"V_pred\", \"A_pred\", \"D_pred\"]).round(2)\n",
    "\n",
    "# Concatenate real and predicted values\n",
    "train_comparison = pd.concat([y_train.reset_index(drop=True), y_train_pred_df], axis=1)\n",
    "val_comparison = pd.concat([y_val.reset_index(drop=True), y_val_pred_df], axis=1)\n",
    "test_comparison = pd.concat([y_test.reset_index(drop=True), y_test_pred_df], axis=1)\n",
    "\n",
    "# Print comparison tables\n",
    "print(\"Training Data Comparison:\\n\", train_comparison.head())\n",
    "print(\"\\nValidation Data Comparison:\\n\", val_comparison.head())\n",
    "print(\"\\nTest Data Comparison:\\n\", test_comparison.head())\n",
    "\n",
    "# Save the comparison tables to CSV files\n",
    "train_comparison.to_csv(\"train_comparison_RF_small.csv\", index=False)\n",
    "val_comparison.to_csv(\"val_comparison_chain_RF_small.csv\", index=False)\n",
    "\n",
    "test_comparison.to_csv(\"test_comparison_chain_RF_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7323a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
