{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb82a5d",
   "metadata": {},
   "source": [
    "### Sequential Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d535609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'split', 'V', 'A', 'D', 'text'], dtype='object')\n",
      "\n",
      "(9906, 6)\n",
      "                    id  split     V     A     D  \\\n",
      "0  110CYL068_1036_1079  train  3.00  3.00  3.20   \n",
      "1  110CYL068_1079_1110   test  2.80  3.10  2.80   \n",
      "2  110CYL068_1127_1130  train  3.00  3.00  3.00   \n",
      "3  110CYL068_1137_1188  train  3.44  3.00  3.22   \n",
      "4  110CYL068_1189_1328  train  3.55  3.27  3.46   \n",
      "\n",
      "                                                text  \n",
      "0        Remember what she said in my last letter? \"  \n",
      "1                          If I wasn't working here.  \n",
      "2                                                ..\"  \n",
      "3  Goodwill helps people get off of public assist...  \n",
      "4  Sherry learned through our Future Works class ...  \n",
      "\n",
      "id        object\n",
      "split     object\n",
      "V        float64\n",
      "A        float64\n",
      "D        float64\n",
      "text      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "data_01=pd.read_csv('Emo_Bank_VAD.csv')\n",
    "\n",
    "print(data_01.columns)\n",
    "print('')\n",
    "print(data_01.shape)\n",
    "print(data_01.head())\n",
    "print('')\n",
    "print(data_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2e15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: (8023,) (892,) (991,) (8023,) (892,) (991,)\n",
      "\n",
      "Evaluation metrics\n",
      "Train RMSE for Valence : 0.21\n",
      "Train MSE for Valence : 0.04\n",
      "Train MAE for Valence: 0.15\n",
      "\n",
      "Validation RMSE for Valence: 0.3\n",
      "Validation MSE for Valence: 0.09\n",
      "Validation MAE for Valence: 0.22\n",
      "\n",
      "Test RMSE for Valence: 0.3\n",
      "Test MSE for Valence: 0.09\n",
      "Test MAE for Valence: 0.22\n"
     ]
    }
   ],
   "source": [
    "#First regression: Predict \"V\" from \"text\"\n",
    "\n",
    "# train, validation and test split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_01[\"text\"], data_01[\"V\"], test_size = 0.1, shuffle=True, random_state = 1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, shuffle=True, random_state = 1) \n",
    "print(\"Data shapes:\", x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# Create a pipeline that includes TfidfVectorizer and Ridge Regression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=7000)),  \n",
    "    ('ridge', Ridge(alpha=1)) \n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_v = pipeline.predict(x_train)\n",
    "y_pred_val_v = pipeline.predict(x_val)\n",
    "y_pred_test_v = pipeline.predict(x_test)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "print()\n",
    "print(\"Evaluation metrics\")\n",
    "print(\"Train RMSE for Valence :\", round(rmse(y_train, y_pred_train_v),2))\n",
    "print(\"Train MSE for Valence :\", round(mean_squared_error(y_train, y_pred_train_v),2))\n",
    "print(\"Train MAE for Valence:\", round(mean_absolute_error(y_train, y_pred_train_v),2))\n",
    "print()\n",
    "print(\"Validation RMSE for Valence:\", round(rmse(y_val, y_pred_val_v),2))\n",
    "print(\"Validation MSE for Valence:\", round(mean_squared_error(y_val, y_pred_val_v),2))\n",
    "print(\"Validation MAE for Valence:\", round(mean_absolute_error(y_val, y_pred_val_v),2))\n",
    "print()\n",
    "print(\"Test RMSE for Valence:\", round(rmse(y_test, y_pred_test_v),2))\n",
    "print(\"Test MSE for Valence:\", round(mean_squared_error(y_test, y_pred_test_v),2))\n",
    "print(\"Test MAE for Valence:\", round(mean_absolute_error(y_test, y_pred_test_v),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add1bba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Comparison:\n",
      "      Actual_V  Predicted_V\n",
      "5214      3.00         3.02\n",
      "4784      2.50         2.70\n",
      "708       2.30         2.71\n",
      "6369      3.56         3.47\n",
      "2135      3.00         3.00\n",
      "\n",
      "Validation Set Comparison:\n",
      "      Actual_V  Predicted_V\n",
      "7794      3.10         3.18\n",
      "6770      2.90         3.03\n",
      "3444      3.00         2.50\n",
      "1767      3.11         2.91\n",
      "8128      3.00         2.95\n",
      "\n",
      "Test Set Comparison:\n",
      "      Actual_V  Predicted_V\n",
      "8687       2.9         3.05\n",
      "7972       2.6         2.88\n",
      "1628       3.0         2.97\n",
      "8699       2.9         2.85\n",
      "5648       3.0         3.07\n"
     ]
    }
   ],
   "source": [
    "#Compare predictions with true values\n",
    "\n",
    "# Training set \n",
    "train_comparison = pd.DataFrame({\n",
    "    'Actual_V': y_train,\n",
    "    'Predicted_V': np.round(y_pred_train_v, 2)})\n",
    "\n",
    "# Validation set \n",
    "val_comparison = pd.DataFrame({\n",
    "    'Actual_V': y_val,\n",
    "    'Predicted_V': np.round(y_pred_val_v, 2)\n",
    "})\n",
    "\n",
    "# Test set \n",
    "test_comparison = pd.DataFrame({\n",
    "    'Actual_V': y_test,\n",
    "    'Predicted_V': np.round(y_pred_test_v, 2)\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Training Set Comparison:\")\n",
    "print(train_comparison.head())  \n",
    "\n",
    "print(\"\\nValidation Set Comparison:\")\n",
    "print(val_comparison.head())  \n",
    "\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "print(test_comparison.head()) \n",
    "\n",
    "\n",
    "# Save the comparison tables to CSV files\n",
    "train_comparison.to_csv(\"train_comparison_seq.csv\", index=False)\n",
    "val_comparison.to_csv(\"val_comparison_chain_seq.csv\", index=False)\n",
    "test_comparison.to_csv(\"test_comparison_chain_seq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f05688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics\n",
      "Train RMSE for predicting Arousal: 0.18\n",
      "Train MSE for predicting Arousal: 0.03\n",
      "Train MAE for predicting Arousal: 0.14\n",
      "\n",
      "Validation RMSE for predicting Arousal: 0.25\n",
      "Validation MSE for predicting Arousal: 0.06\n",
      "Validation MAE for predicting Arousal: 0.19\n",
      "\n",
      "Test RMSE for predicting Arousal: 0.26\n",
      "Test MSE for predicting Arousal: 0.07\n",
      "Test MAE for predicting Arousal: 0.19\n"
     ]
    }
   ],
   "source": [
    "#Predict \"A\" for \"text\" and predictions of \"V\"\n",
    "\n",
    "# Create DataFrames with text and the predicted \"V\" values\n",
    "train_data = pd.DataFrame({\n",
    "    'text': x_train,\n",
    "    'predicted_V': y_pred_train_v,\n",
    "    'A': data_01.loc[x_train.index, 'A']\n",
    "})\n",
    "val_data = pd.DataFrame({\n",
    "    'text': x_val,\n",
    "    'predicted_V': y_pred_val_v,\n",
    "    'A': data_01.loc[x_val.index, 'A']\n",
    "})\n",
    "test_data = pd.DataFrame({\n",
    "    'text': x_test,\n",
    "    'predicted_V': y_pred_test_v,\n",
    "    'A': data_01.loc[x_test.index, 'A']\n",
    "})\n",
    "\n",
    "# Combine text and predicted_V as features\n",
    "def transform_features(data, tfidf_vectorizer):\n",
    "    text_features = tfidf_vectorizer.transform(data['text'])\n",
    "    predicted_V_features = np.expand_dims(data['predicted_V'].values, axis=1)\n",
    "    return np.hstack((text_features.toarray(), predicted_V_features))\n",
    "\n",
    "# Fit TF-IDF vectorizer on the text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=7000)\n",
    "tfidf_vectorizer.fit(data_01[\"text\"]) \n",
    "\n",
    "# Transform features\n",
    "X_train_a = transform_features(train_data, tfidf_vectorizer)\n",
    "X_val_a = transform_features(val_data, tfidf_vectorizer)\n",
    "X_test_a = transform_features(test_data, tfidf_vectorizer)\n",
    "\n",
    "# Train Ridge Regression model for predicting \"A\"\n",
    "y_train_a = train_data['A']\n",
    "y_val_a = val_data['A']\n",
    "y_test_a = test_data['A']\n",
    "\n",
    "pipeline_a = Ridge(alpha=1)\n",
    "pipeline_a.fit(X_train_a, y_train_a)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_a = pipeline_a.predict(X_train_a)\n",
    "y_pred_val_a = pipeline_a.predict(X_val_a)\n",
    "y_pred_test_a = pipeline_a.predict(X_test_a)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print()\n",
    "print(\"Evaluation metrics\")\n",
    "print(\"Train RMSE for predicting Arousal:\", round(rmse(y_train_a, y_pred_train_a), 2))\n",
    "print(\"Train MSE for predicting Arousal:\", round(mean_squared_error(y_train_a, y_pred_train_a), 2))\n",
    "print(\"Train MAE for predicting Arousal:\", round(mean_absolute_error(y_train_a, y_pred_train_a), 2))\n",
    "print()\n",
    "print(\"Validation RMSE for predicting Arousal:\", round(rmse(y_val_a, y_pred_val_a), 2))\n",
    "print(\"Validation MSE for predicting Arousal:\", round(mean_squared_error(y_val_a, y_pred_val_a), 2))\n",
    "print(\"Validation MAE for predicting Arousal:\", round(mean_absolute_error(y_val_a, y_pred_val_a), 2))\n",
    "print()\n",
    "print(\"Test RMSE for predicting Arousal:\", round(rmse(y_test_a, y_pred_test_a), 2))\n",
    "print(\"Test MSE for predicting Arousal:\", round(mean_squared_error(y_test_a, y_pred_test_a), 2))\n",
    "print(\"Test MAE for predicting Arousal:\", round(mean_absolute_error(y_test_a, y_pred_test_a), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f61de20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Comparison:\n",
      "      Actual_A  Predicted_A\n",
      "5214      2.70         2.93\n",
      "4784      3.10         3.05\n",
      "708       3.10         3.17\n",
      "6369      3.33         3.22\n",
      "2135      3.00         3.01\n",
      "\n",
      "Validation Set Comparison:\n",
      "      Actual_A  Predicted_A\n",
      "7794      3.10         3.23\n",
      "6770      2.90         3.03\n",
      "3444      3.43         3.01\n",
      "1767      3.00         2.96\n",
      "8128      3.20         3.01\n",
      "\n",
      "Test Set Comparison:\n",
      "      Actual_A  Predicted_A\n",
      "8687      2.20         3.17\n",
      "7972      3.20         3.02\n",
      "1628      2.86         2.93\n",
      "8699      2.70         2.93\n",
      "5648      2.78         2.98\n"
     ]
    }
   ],
   "source": [
    "# Training set \n",
    "train_comparison = pd.DataFrame({\n",
    "    'Actual_A': y_train_a,\n",
    "    'Predicted_A': np.round(y_pred_train_a, 2)})\n",
    "\n",
    "# Validation set \n",
    "val_comparison = pd.DataFrame({\n",
    "    'Actual_A': y_val_a,\n",
    "    'Predicted_A': np.round(y_pred_val_a, 2)\n",
    "})\n",
    "\n",
    "# Test set \n",
    "test_comparison = pd.DataFrame({\n",
    "    'Actual_A': y_test_a,\n",
    "    'Predicted_A': np.round(y_pred_test_a, 2)\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Training Set Comparison:\")\n",
    "print(train_comparison.head())  \n",
    "\n",
    "print(\"\\nValidation Set Comparison:\")\n",
    "print(val_comparison.head())  \n",
    "\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "print(test_comparison.head()) \n",
    "\n",
    "\n",
    "# Save the comparison tables to CSV files\n",
    "train_comparison.to_csv(\"train_comparison_seqVA.csv\", index=False)\n",
    "val_comparison.to_csv(\"val_comparison_chain_seqVA.csv\", index=False)\n",
    "test_comparison.to_csv(\"test_comparison_chain_seqVA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21606992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics\n",
      "Train RMSE for predicting 'D': 0.15\n",
      "Train MSE for predicting 'D': 0.02\n",
      "Train MAE for predicting 'D': 0.11\n",
      "\n",
      "Validation RMSE for predicting 'D': 0.22\n",
      "Validation MSE for predicting 'D': 0.05\n",
      "Validation MAE for predicting 'D': 0.17\n",
      "\n",
      "Test RMSE for predicting 'D': 0.22\n",
      "Test MSE for predicting 'D': 0.05\n",
      "Test MAE for predicting 'D': 0.17\n"
     ]
    }
   ],
   "source": [
    "#Predict \"D\" from \"text\" and predictions of \"V\" and \"A\"\n",
    "\n",
    "# Create DataFrames with text, predicted \"V\", predicted \"A\", and the target \"D\"\n",
    "train_data = pd.DataFrame({\n",
    "    'text': x_train,\n",
    "    'predicted_V': y_pred_train_v,\n",
    "    'predicted_A': y_pred_train_a,\n",
    "    'D': data_01.loc[x_train.index, 'D'] \n",
    "})\n",
    "val_data = pd.DataFrame({\n",
    "    'text': x_val,\n",
    "    'predicted_V': y_pred_val_v,\n",
    "    'predicted_A': y_pred_val_a,\n",
    "    'D': data_01.loc[x_val.index, 'D']  \n",
    "})\n",
    "test_data = pd.DataFrame({\n",
    "    'text': x_test,\n",
    "    'predicted_V': y_pred_test_v,\n",
    "    'predicted_A': y_pred_test_a,\n",
    "    'D': data_01.loc[x_test.index, 'D']  \n",
    "})\n",
    "\n",
    "# Fit TF-IDF vectorizer on the entire text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=7000)\n",
    "tfidf_vectorizer.fit(data_01[\"text\"])  \n",
    "\n",
    "# Define a function to combine text features with predicted_V and predicted_A\n",
    "def transform_features(data, tfidf_vectorizer):\n",
    "    text_features = tfidf_vectorizer.transform(data['text'])\n",
    "    predicted_V_features = np.expand_dims(data['predicted_V'].values, axis=1)\n",
    "    predicted_A_features = np.expand_dims(data['predicted_A'].values, axis=1)\n",
    "    return np.hstack((text_features.toarray(), predicted_V_features, predicted_A_features))\n",
    "\n",
    "# Transform features for training, validation, and test sets\n",
    "X_train_final = transform_features(train_data, tfidf_vectorizer)\n",
    "X_val_final = transform_features(val_data, tfidf_vectorizer)\n",
    "X_test_final = transform_features(test_data, tfidf_vectorizer)\n",
    "\n",
    "# Train a new Ridge Regression model to predict \"D\"\n",
    "y_train_d = train_data['D']\n",
    "y_val_d = val_data['D']\n",
    "y_test_d = test_data['D']\n",
    "\n",
    "pipeline_d = Ridge(alpha=1)\n",
    "pipeline_d.fit(X_train_final, y_train_d)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_d = pipeline_d.predict(X_train_final)\n",
    "y_pred_val_d = pipeline_d.predict(X_val_final)\n",
    "y_pred_test_d = pipeline_d.predict(X_test_final)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Evaluate the new model\n",
    "print(\"Evaluation metrics\")\n",
    "print(\"Train RMSE for predicting 'D':\", round(rmse(y_train_d, y_pred_train_d), 2))\n",
    "print(\"Train MSE for predicting 'D':\", round(mean_squared_error(y_train_d, y_pred_train_d), 2))\n",
    "print(\"Train MAE for predicting 'D':\", round(mean_absolute_error(y_train_d, y_pred_train_d), 2))\n",
    "print()\n",
    "print(\"Validation RMSE for predicting 'D':\", round(rmse(y_val_d, y_pred_val_d), 2))\n",
    "print(\"Validation MSE for predicting 'D':\", round(mean_squared_error(y_val_d, y_pred_val_d), 2))\n",
    "print(\"Validation MAE for predicting 'D':\", round(mean_absolute_error(y_val_d, y_pred_val_d), 2))\n",
    "print()\n",
    "print(\"Test RMSE for predicting 'D':\", round(rmse(y_test_d, y_pred_test_d), 2))\n",
    "print(\"Test MSE for predicting 'D':\", round(mean_squared_error(y_test_d, y_pred_test_d), 2))\n",
    "print(\"Test MAE for predicting 'D':\", round(mean_absolute_error(y_test_d, y_pred_test_d), 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af345a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Comparison:\n",
      "      Actual_D  Predicted_D\n",
      "5214      3.10         3.12\n",
      "4784      2.80         2.92\n",
      "708       2.80         2.87\n",
      "6369      3.11         3.15\n",
      "2135      3.00         3.04\n",
      "\n",
      "Validation Set Comparison:\n",
      "      Actual_D  Predicted_D\n",
      "7794      3.80         3.00\n",
      "6770      2.90         3.05\n",
      "3444      3.43         2.96\n",
      "1767      3.22         2.96\n",
      "8128      3.10         3.02\n",
      "\n",
      "Test Set Comparison:\n",
      "      Actual_D  Predicted_D\n",
      "8687       2.9         3.03\n",
      "7972       2.9         3.09\n",
      "1628       3.0         3.07\n",
      "8699       3.1         2.95\n",
      "5648       3.0         3.13\n"
     ]
    }
   ],
   "source": [
    "# Compare predicted and real values for each set\n",
    "\n",
    "#Training set \n",
    "train_comparison = pd.DataFrame({\n",
    "    'Actual_D': y_train_d,\n",
    "    'Predicted_D': np.round(y_pred_train_d, 2)  \n",
    "})\n",
    "\n",
    "# Validation set comparison\n",
    "val_comparison = pd.DataFrame({\n",
    "    'Actual_D': y_val_d,\n",
    "    'Predicted_D': np.round(y_pred_val_d, 2)  \n",
    "})\n",
    "\n",
    "# Test set comparison\n",
    "test_comparison = pd.DataFrame({\n",
    "    'Actual_D': y_test_d,\n",
    "    'Predicted_D': np.round(y_pred_test_d, 2)  \n",
    "})\n",
    "\n",
    "# Display the tables\n",
    "print(\"Training Set Comparison:\")\n",
    "print(train_comparison.head())  \n",
    "\n",
    "print(\"\\nValidation Set Comparison:\")\n",
    "print(val_comparison.head())  \n",
    "\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "print(test_comparison.head())  \n",
    "\n",
    "# Save the comparison tables to CSV files\n",
    "train_comparison.to_csv(\"train_comparison_seqVAD.csv\", index=False)\n",
    "val_comparison.to_csv(\"val_comparison_chain_seqVAD.csv\", index=False)\n",
    "test_comparison.to_csv(\"test_comparison_chain_seqVAD.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
