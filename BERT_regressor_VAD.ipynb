{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063b31de",
   "metadata": {},
   "source": [
    "### BERT regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979306f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id split     V     A     D text\n",
      "8281  easy_money_13624_13628   dev  2.78  2.89  2.78  NaN\n",
      "Data shapes: (8022,) (892,) (991,) (8022, 3) (892, 3) (991, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the dataset, check and remove null values\n",
    "data_01 = pd.read_csv('Emo_Bank_VAD.csv')\n",
    "null_rows = data_01[data_01['text'].isnull()]\n",
    "print(null_rows)\n",
    "data_01 = data_01.dropna(subset=['text'])\n",
    "data_01.isnull().sum()\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_01[\"text\"], data_01[[\"V\", \"A\", \"D\"]], test_size=0.1, shuffle=True, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, shuffle=True, random_state=1)\n",
    "print(\"Data shapes:\", x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c50f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 11:10:18.591542: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-27 11:10:18.591573: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-12-27 11:10:18.591581: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-12-27 11:10:18.591673: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-27 11:10:18.591929: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#tokenize and pad\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 170\n",
    "x_train_pad = tokenizer(x_train.tolist(), padding='max_length', truncation=True, max_length=170, return_tensors=\"tf\")\n",
    "x_val_pad = tokenizer(x_val.tolist(), padding='max_length', truncation=True, max_length=170, return_tensors=\"tf\")\n",
    "x_test_pad = tokenizer(x_test.tolist(), padding='max_length', truncation=True, max_length=170, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2cebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load BERT model \n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the model\n",
    "def create_model():\n",
    "    # BERT input/output layers\n",
    "    input_ids = Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = bert_output.pooler_output  \n",
    "\n",
    "    # Dense layer for regression\n",
    "    dense = Dense(64, activation='relu')(pooled_output)  \n",
    "    output = Dense(3, activation='tanh')(dense)  # Output layer for 3 values (V, A, D), using 'tanh' to stay in range [-1, 1]\n",
    "\n",
    "    # Define the complete model\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_BERT = create_model()\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "model_BERT.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n",
    "              loss='mean_squared_error', \n",
    "              metrics=['mae']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc4e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "502/502 [==============================] - 1006s 2s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 1073s 2s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 1091s 2s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 27220s 54s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 1055s 2s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 966s 2s/step - loss: 4.1953 - mae: 2.0289 - val_loss: 4.1761 - val_mae: 2.0240\n",
      "31/31 [==============================] - 38s 1s/step - loss: 4.1504 - mae: 2.0175\n",
      "Test MSE: 4.150419235229492, Test MAE: 2.0174574851989746\n",
      "31/31 [==============================] - 39s 1s/step\n",
      "Mean Squared Error: 4.150418706782473, Mean Absolute Error: 2.017457382898718\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model_BERT.fit(\n",
    "    x={'input_ids': x_train_pad['input_ids'], 'attention_mask': x_train_pad['attention_mask']},\n",
    "    y=y_train,\n",
    "    validation_data=({'input_ids': x_val_pad['input_ids'], 'attention_mask': x_val_pad['attention_mask']}, y_val),\n",
    "    epochs=6,  \n",
    "    batch_size=16  \n",
    ")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_mae = model_BERT.evaluate({'input_ids': x_test_pad['input_ids'], 'attention_mask': x_test_pad['attention_mask']}, y_test)\n",
    "print(f\"Test MSE: {test_loss}, Test MAE: {test_mae}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_BERT.predict({'input_ids': x_test_pad['input_ids'], 'attention_mask': x_test_pad['attention_mask']})\n",
    "\n",
    "# Compute additional evaluation metrics like MSE and MAE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}, Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f88fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 34s 1s/step\n",
      "Test Dataset Evaluation:\n",
      "RMSE for V: 1.99\n",
      "RMSE for A: 2.05\n",
      "RMSE for D: 2.07\n",
      "\n",
      "MAE for V: 1.96\n",
      "MAE for A: 2.04\n",
      "MAE for D: 2.06\n",
      "\n",
      "MSE for V: 3.96\n",
      "MSE for A: 4.21\n",
      "MSE for D: 4.28\n",
      "\n",
      "Test Data Comparison:\n",
      "       V     A    D  V_pred  A_pred  D_pred\n",
      "0  3.00  3.00  3.0     1.0     1.0     1.0\n",
      "1  2.90  3.00  3.3     1.0     1.0     1.0\n",
      "2  2.44  3.22  3.0     1.0     1.0     1.0\n",
      "3  3.40  3.00  3.1     1.0     1.0     1.0\n",
      "4  2.70  3.10  2.9     1.0     1.0     1.0\n"
     ]
    }
   ],
   "source": [
    "# Ensure that y_test is converted to a numpy array\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Predict on the tokenized test set using the trained BERT model\n",
    "y_pred = model_BERT.predict({'input_ids': x_test_pad['input_ids'], 'attention_mask': x_test_pad['attention_mask']})\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "y_pred_np = np.array(y_pred)\n",
    "\n",
    "# Define RMSE function\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Evaluate performance\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    metrics = {}\n",
    "    metrics['RMSE_V'] = rmse(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['RMSE_A'] = rmse(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['RMSE_D'] = rmse(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    metrics['MAE_V'] = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['MAE_A'] = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['MAE_D'] = mean_absolute_error(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    metrics['MSE_V'] = mean_squared_error(y_true[:, 0], y_pred[:, 0])\n",
    "    metrics['MSE_A'] = mean_squared_error(y_true[:, 1], y_pred[:, 1])\n",
    "    metrics['MSE_D'] = mean_squared_error(y_true[:, 2], y_pred[:, 2])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate performance metrics for the test dataset\n",
    "test_metrics = evaluate_performance(y_test_np, y_pred_np)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Test Dataset Evaluation:\")\n",
    "print(f'RMSE for V: {round(test_metrics[\"RMSE_V\"], 2)}')\n",
    "print(f'RMSE for A: {round(test_metrics[\"RMSE_A\"], 2)}')\n",
    "print(f'RMSE for D: {round(test_metrics[\"RMSE_D\"], 2)}\\n')\n",
    "print(f'MAE for V: {round(test_metrics[\"MAE_V\"], 2)}')\n",
    "print(f'MAE for A: {round(test_metrics[\"MAE_A\"], 2)}')\n",
    "print(f'MAE for D: {round(test_metrics[\"MAE_D\"], 2)}\\n')\n",
    "print(f'MSE for V: {round(test_metrics[\"MSE_V\"], 2)}')\n",
    "print(f'MSE for A: {round(test_metrics[\"MSE_A\"], 2)}')\n",
    "print(f'MSE for D: {round(test_metrics[\"MSE_D\"], 2)}\\n')\n",
    "\n",
    "# Convert predictions to DataFrame and round to two decimal places\n",
    "y_pred_df = pd.DataFrame(y_pred_np, columns=[\"V_pred\", \"A_pred\", \"D_pred\"]).round(2)\n",
    "\n",
    "# Concatenate real and predicted values for comparison\n",
    "test_comparison = pd.concat([y_test.reset_index(drop=True), y_pred_df], axis=1)\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Test Data Comparison:\\n\", test_comparison.head())\n",
    "\n",
    "# Save the comparison table to a CSV file\n",
    "test_comparison.to_csv(\"test_comparison_BERT_regression_03.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef97289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
