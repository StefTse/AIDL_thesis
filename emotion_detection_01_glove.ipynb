{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1154b999",
   "metadata": {},
   "source": [
    "### Emotional annotation using VAD \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72197b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stef_tse/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stef_tse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    text = nltk.word_tokenize(text.lower())  # Lowercase and tokenize\n",
    "    text = [w for w in text if not w in stop_words]  # Remove stop words\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", text)  # Remove unwanted characters\n",
    "    text = re.sub(r\"\\s+\", r\" \", text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "490974b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify V, A, D\n",
    "def classify_variable(value, var_type):\n",
    "    if var_type == \"V\":  # Valence\n",
    "        if -1.0 <= value <= -0.6:\n",
    "            return \"highly negative\"\n",
    "        elif -0.6 < value <= -0.2:\n",
    "            return \"moderately negative\"\n",
    "        elif -0.2 < value <= 0.2:\n",
    "            return \"neutral\"\n",
    "        elif 0.2 < value <= 0.6:\n",
    "            return \"moderately positive\"\n",
    "        elif 0.6 < value <= 1.0:\n",
    "            return \"highly positive\"\n",
    "    elif var_type == \"A\":  # Arousal\n",
    "        if -1.0 <= value <= -0.6:\n",
    "            return \"inactive\"\n",
    "        elif -0.6 < value <= -0.2:\n",
    "            return \"low arousal\"\n",
    "        elif -0.2 < value <= 0.2:\n",
    "            return \"neutral\"\n",
    "        elif 0.2 < value <= 0.6:\n",
    "            return \"moderate arousal\"\n",
    "        elif 0.6 < value <= 1.0:\n",
    "            return \"high arousal\"\n",
    "    elif var_type == \"D\":  # Dominance\n",
    "        if -1.0 <= value <= -0.6:\n",
    "            return \"poor dominance\"\n",
    "        elif -0.6 < value <= -0.2:\n",
    "            return \"low dominance\"\n",
    "        elif -0.2 < value <= 0.2:\n",
    "            return \"neutral\"\n",
    "        elif 0.2 < value <= 0.6:\n",
    "            return \"moderate dominance\"\n",
    "        elif 0.6 < value <= 1.0:\n",
    "            return \"high dominance\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59718f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"best_model_with_glove.h5\"\n",
    "\n",
    "# MSE metric\n",
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "# RMSE metric (if required for model loading)\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Load the model once and prepare tokenizer\n",
    "def load_model_and_tokenizer(model_path):\n",
    "    with tf.keras.utils.custom_object_scope({'mse': mse, 'rmse': rmse}):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to predict and describe\n",
    "def predict_and_describe(model, tokenizer, input_text):\n",
    "    words = input_text.split()\n",
    "    if len(words) > 170:\n",
    "        input_text = \" \".join(words[:170])\n",
    "    \n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess(input_text)\n",
    "    \n",
    "    # Convert text data to sequences\n",
    "    tokenizer.fit_on_texts([preprocessed_text])  # Fit the tokenizer on the preprocessed text\n",
    "    preprocessed_text_seq = tokenizer.texts_to_sequences([preprocessed_text])\n",
    "    \n",
    "    max_length = 170\n",
    "    padded_input = pad_sequences(preprocessed_text_seq, maxlen=max_length)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model(tf.constant(padded_input))[0]\n",
    "    predictions = predictions.numpy().flatten()\n",
    "    \n",
    "    # Extract V, A, D values\n",
    "    V, A, D = predictions[0], predictions[1], predictions[2]\n",
    "    \n",
    "    # Classify each variable\n",
    "    V_category = classify_variable(V, \"V\")\n",
    "    A_category = classify_variable(A, \"A\")\n",
    "    D_category = classify_variable(D, \"D\")\n",
    "    \n",
    "    # Generate description\n",
    "    description = f\"Text Analysis:\\n- Valence (V): {V:.2f} ({V_category})\\n- Arousal (A): {A:.2f} ({A_category})\\n- Dominance (D): {D:.2f} ({D_category})\"\n",
    "    return description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39de891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis:\n",
      "- Valence (V): -0.71 (highly negative)\n",
      "- Arousal (A): 0.63 (high arousal)\n",
      "- Dominance (D): -0.72 (poor dominance)\n"
     ]
    }
   ],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"best_model_with_glove.h5\"  \n",
    "    model, tokenizer = load_model_and_tokenizer(model_path) \n",
    "    \n",
    "    # Usage\n",
    "    input_sentence= \"i am deeply sad\"\n",
    "    \n",
    "    # Predict and describe for different sentences\n",
    "    result= predict_and_describe(model, tokenizer, input_sentence)\n",
    "    \n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4b773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
